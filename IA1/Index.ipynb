{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final IA1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos simplesmente importando tudo que usaremos no código, e carregando ambos os datasets de nosso folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SKlearn imports\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos limpar as features. Precisamos retirar as colunas cujos valores são constantes, e as colunas que são duplicatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are constant\n",
    "remove = []\n",
    "for col in train.columns:\n",
    "    if train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "cols = train.columns\n",
    "for i in range(len(cols)-1):\n",
    "    v = train[cols[i]].values\n",
    "    for j in range(i+1, len(cols)):\n",
    "        if np.array_equal(v, train[cols[j]].values):\n",
    "            remove.append(cols[j])\n",
    "\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# test_id receives the ID column of the test CSV. It is then dropped from test, of course.\n",
    "test_id = test.ID\n",
    "test = test.drop([\"ID\"],axis=1)\n",
    "\n",
    "# similarly, we drop both the target, and the ID from training set. Drop TARGET so as to make learning better.\n",
    "X = train.drop([\"TARGET\",\"ID\"],axis=1)\n",
    "y = train.TARGET.values\n",
    "\n",
    "# similar process to what was done in the entire course so far - split the training into two.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que esta parte do código é extremamente simples. Retirar colunas constantes e colunas duplicatas é sempre algo que deva ser feito o mais cedo possível, para que não haja problema na hora de treinar os modelos com features desnecessárias. Faz parte do processo de analisar e aplicar feature engineering nos datasets.\n",
    "\n",
    "Também, no final do código acima, simplesmente dropamos o ID da coluna de testes (desnecessário) e o salvamos em uma outra variável (para utilizar mais tarde, na submissão). E, de forma similar, dropamos não só o ID mas também o TARGET da nossa classe de treino (retirar o TARGET para podermos treinar, obviamente).\n",
    "\n",
    "Por fim, dividimos o treino em dois, com 20% sendo utilizado para testar o fit do modelo, e 80% sendo realmente utilizado para treino. Isto é algo que foi feito ao longo de toda a disciplina, logo não há muito o que explicar.\n",
    "\n",
    "A seguir, escolheremos quais features iremos utilizar dentre as restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we select the features we'll be utilizing to train our model.\n",
    "clf = ExtraTreesClassifier(random_state=1729)\n",
    "selector = clf.fit(X_train, y_train)\n",
    "\n",
    "# selects the most important features we found through the extra tree classifier\n",
    "fs = SelectFromModel(selector, prefit=True)\n",
    "print(X_train.shape)\n",
    "# reduces X_train and X_test to these features only.\n",
    "X_train = fs.transform(X_train)\n",
    "X_test = fs.transform(X_test)\n",
    "test = fs.transform(test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte do código, utilizamos o ExtraTreeClassifier. Mas o que é o ExtraTreeClassifier?\n",
    "\n",
    "O ExtraTreeClassifier gera e treina diversas árvores de decisões, em várias partições do arquivo de entrada, de tal forma a minimizar o overfit. Ao fitarmos esse modelo de ExtraTreesClassifier, estamos recebendo de volta uma floresta com as árvores criadas e treinadas. Ela é utilizada para treinar e descobrir quais features são mais importantes.\n",
    "\n",
    "Por sua vez, o SelectFromModel é uma função para transformar nossas bases de dados. Como parametro, recebe o seletor de features que acabamos de criar. \"Prefit\" é \"True\" pois a árvore já foi previamente \"fitada\", ou treinada.\n",
    "\n",
    "A função \"transform\", por fim, reduzirá todos os nossos datasets para conter apenas as features que julga necessárias.\n",
    "\n",
    "Utilizando o print (X_train.shape), que nos diz qual a dimensão do nosso dataset, podemos perceber que antes de utilizarmos a função Transform no Dataset, haviam 306 colunas. Após o transform, restam apenas 36, que nosso ExtraTreesClassifier julgou útil. Não sabemos quais são estas features, porém, isto não é importante - dado que as features em si são \"secretas\" e os nomes são apenas nomes quaisquer, não há mérito em saber o que cada feature é a não ser curiosidade. Poderíamos plotar cada feature e descobrir qual o peso de cada sua importância, mas creio não ser necessário. Não é difícil, também, logo poderia ser implementado facilmente com um plot.\n",
    "\n",
    "Com tudo isto feito, o que resta é utilizar Bagging, Stacking, e Ensemble para treinar diversos modelos e avaliar suas eficácias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "\n",
    "\n",
    "# ALL SCORES FROM THE PRIVATE LEADERBOARD.\n",
    "\n",
    "\n",
    "# XGB model. Private score: 0.819772\n",
    "\n",
    "XGBmodel = xgb.XGBClassifier(n_estimators=110, nthread=-1, max_depth=4, seed=1729)\n",
    "XGBmodel.fit(X_train, y_train, eval_metric=\"auc\", verbose=False, eval_set=[(X_test, y_test)])\n",
    "y_pred = XGBmodel.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionXGB.csv\", index=False)\n",
    "\n",
    "# KNN model. Private Score: 0.563689\n",
    "\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=3, weights=\"distance\")\n",
    "KNNmodel.fit(X_train, y_train)\n",
    "y_pred = KNNmodel.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionKNN.csv\", index=False)\n",
    "\n",
    "# Bagged KNN. Private Score: 0.661960.\n",
    "\n",
    "baggedKNN = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5, random_state=38)\n",
    "baggedKNN.fit(X_train, y_train)\n",
    "y_pred = baggedKNN.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionBaggedKNN.csv\", index=False)\n",
    "\n",
    "# MLPClassifier. Private Score: 0.535727\n",
    "\n",
    "MLPCmodel = MLPClassifier(random_state=38)\n",
    "MLPCmodel.fit(X_train, y_train)\n",
    "y_pred = MLPCmodel.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionMLPC.csv\", index=False)\n",
    "\n",
    "# MLPclassifier (bagged). Private score: 0.701536\n",
    "\n",
    "baggedMLPC = BaggingClassifier(MLPClassifier(random_state=38), max_samples=0.5, max_features=0.5, random_state=38)\n",
    "baggedMLPC.fit(X_train, y_train)\n",
    "y_pred = baggedMLPC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionBaggedMLPC.csv\", index=False)\n",
    "\n",
    "# GBClassifier. Private Score: 0.818242\n",
    "\n",
    "GBCmodel = GradientBoostingClassifier(random_state=38)\n",
    "GBCmodel.fit(X_train, y_train)\n",
    "y_pred = GBCmodel.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionGBC.csv\", index=False)\n",
    "\n",
    "# GBClassifier BAGGED. Private Score: 0.776595)\n",
    "\n",
    "baggedGBC = BaggingClassifier(GradientBoostingClassifier(random_state=38), max_samples=0.5, max_features=0.5,\n",
    "                             random_state=38)\n",
    "baggedGBC.fit(X_train, y_train)\n",
    "y_pred = baggedGBC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionBaggedGBC.csv\", index=False)\n",
    "\n",
    "# DTClassifier. Private Score: 0.572142\n",
    "\n",
    "DTCmodel = DecisionTreeClassifier(random_state=38, criterion=\"entropy\")\n",
    "DTCmodel.fit(X_train, y_train)\n",
    "y_pred = DTCmodel.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionDTC.csv\", index=False)\n",
    "\n",
    "# DTClassifier BAGGED. Private Score: 0.701126\n",
    "\n",
    "baggedDTC = BaggingClassifier(DecisionTreeClassifier(random_state=38), max_samples=0.5, max_features=0.5, random_state=38)\n",
    "baggedDTC.fit(X_train, y_train)\n",
    "y_pred = baggedDTC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionBaggedDTC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima vemos o stacking e o bagging de modelos, mas ainda sem um ensemble para todos. O bagging utilizado aqui é apenas para a criação de diversos modelos, aumentando sua eficácia agregando os resultados para minimizar a variância. \n",
    "\n",
    "Vemos que, de forma geral, o Bagging melhora a vasta maioria de todos os modelos testados, tendo melhoria de até 17% (como no caso da rede neural, MLPClassifier, que utiliza multilayer perceptrons como já visto em sala). A única exceção a esta regra é o GradientBoostClassifier, que piora levemente com a utilização do Bagging.\n",
    "\n",
    "Por sua vez, podemos perceber que o GBClassifier está bem próximo ao XGBoost, enquanto DecisionTreeClassifier, KNearestNeighbors, e o próprio MLPClassifier (sem bagging) estão significativamente piores.\n",
    "\n",
    "Em relação aos valores com a utilização de Bagging, GBClassifier continua com o maior score dentre os baggings utilizados, porém é o único com uma piora - todos os outros modelos obtem uma melhoria, com o MLPClassifer e o DTClassifier estando bem próximos. KNN continua, porém, significativamente atrás. \n",
    "\n",
    "De forma geral, a ordem dos modelos treinados individualmente, em eficiência, segue desta forma:\n",
    "\n",
    "1. XGBoost - 0.819772\n",
    "2. GBClassifier - 0.818242\n",
    "3. GBClassifier com Bagging - 0.776595\n",
    "4. MLPClassifier com Bagging - 0.701536\n",
    "5. DTClassifier com Bagging - 0.701126\n",
    "6. KNN com Bagging - 0.661960\n",
    "7. DTClassifier - 0.572142\n",
    "8. MLPClassifier - 0.535727\n",
    "9. KNN - 0.563689\n",
    "\n",
    "Nota-se que a melhor melhora com a utilização de bagging é vista no MLPClassifier.\n",
    "\n",
    "Para analisar estes modelos, não mudamos os parâmetros destes. Como o objetivo era analisar as diferenças de baggings, não havia porque mexer nos parâmetros individuais de cada modelo, dado que a ênfase deste trabalho está em analisar a diferença do modelo por si só e com a utilização de bagging, e não sua eficácia com diversos parâmetros.\n",
    "\n",
    "Todos os scores aqui colocados são os resultados obtidos na Leaderboard Privada do kaggle.\n",
    "\n",
    "Por fim, temos então a utilização do Ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembling everything (VOTING CLASSIFIER....)\n",
    "# --------------------------------------------------------------------\n",
    "# first lets try ensembling with no baggings... Private Score: 0.781657\n",
    "\n",
    "ensembleVC = VotingClassifier(estimators=[('xgb', XGBmodel), ('knn', KNNmodel), ('mlpc', MLPCmodel), ('gbc', GBCmodel)\n",
    "                                           ,('dtc', DTCmodel)], voting=\"soft\")\n",
    "ensembleVC.fit(X_test, y_test)\n",
    "y_pred = ensembleVC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionensembleNoBags.csv\", index=False)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# now let us ensemble with only baggings... private Score: 0.769105\n",
    "\n",
    "ensembleVC = VotingClassifier(estimators=[('xgb', XGBmodel), ('knnbag', baggedKNN), ('mlpcbag', baggedMLPC), ('gbcbag', baggedGBC),\n",
    "                                          ('dcbag', baggedDTC)], voting=\"soft\")\n",
    "ensembleVC.fit(X_test, y_test)\n",
    "y_pred = ensembleVC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionensembleOnlyBags.csv\", index=False)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# now, ensembling EVERYTHING... Private Score: 0.763175\n",
    "\n",
    "ensembleVC = VotingClassifier(estimators=[('xgb', XGBmodel), ('knn', KNNmodel), ('knnbag', baggedKNN),\n",
    "                                         ('mlpc', MLPCmodel), ('mlpcbag', baggedMLPC), ('gbc', GBCmodel),\n",
    "                                         ('gbcbag', baggedGBC), ('dtc', DTCmodel), ('dtcbag', baggedDTC)],\n",
    "                              voting=\"soft\");\n",
    "ensembleVC.fit(X_test, y_test)\n",
    "y_pred = ensembleVC.predict_proba(test)\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": y_pred[:, 1]})\n",
    "submission.to_csv(\"submissionensembleALL.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ensemble utilizado foi o VotingClassifier, um ensemble simple de voto de maioria. Ele fita um clone dos modelos (que resultam no mesmo que anteriormente, dado que todos estão utilizando sementes). Cada modelo pode ter um peso, porém aqui, não colocamos nenhum peso em nenhum modelo - isto se deve ao fato de que queremos mostrar que este Ensemble funciona melhor com modelos que possuem uma discrepância significativa, como visto no primeiro resultado (onde utilizamos os modelos sem os baggings, que aumentam de forma visível a eficácia de cada modelo).\n",
    "\n",
    "O parâmetro \"voting=soft\" é utilizado para poder utilizar a função \"predict_proba\", que nos retorna a probabilidade do nosso TARGET, mantendo o sistema consistente com tudo utilizado até então."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
